{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construindo vocabulário a partir do conjunto de treino...\n",
      "Vocabulário construído com 101 tokens mais frequentes.\n",
      "Usando dispositivo: cuda\n",
      "Epoch 1/200 - Loss: 0.6957 - Val Acc: 0.5000 - Val Prec: 0.0000\n",
      "Epoch 2/200 - Loss: 0.6935 - Val Acc: 0.5100 - Val Prec: 0.5051\n",
      "Epoch 3/200 - Loss: 0.6925 - Val Acc: 0.5100 - Val Prec: 0.5051\n",
      "Epoch 4/200 - Loss: 0.6968 - Val Acc: 0.5400 - Val Prec: 0.5208\n",
      "Epoch 5/200 - Loss: 0.6914 - Val Acc: 0.5000 - Val Prec: 0.0000\n",
      "Epoch 6/200 - Loss: 0.6733 - Val Acc: 0.5300 - Val Prec: 0.5155\n",
      "Epoch 7/200 - Loss: 0.6560 - Val Acc: 0.6000 - Val Prec: 0.5714\n",
      "Epoch 8/200 - Loss: 0.6395 - Val Acc: 0.6300 - Val Prec: 0.5890\n",
      "Epoch 9/200 - Loss: 0.5984 - Val Acc: 0.5900 - Val Prec: 0.5495\n",
      "Epoch 10/200 - Loss: 0.6265 - Val Acc: 0.5500 - Val Prec: 0.5263\n",
      "Epoch 11/200 - Loss: 0.6509 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 12/200 - Loss: 0.6317 - Val Acc: 0.7200 - Val Prec: 0.6618\n",
      "Epoch 13/200 - Loss: 0.5402 - Val Acc: 0.8200 - Val Prec: 0.8200\n",
      "Epoch 14/200 - Loss: 0.3872 - Val Acc: 0.9400 - Val Prec: 1.0000\n",
      "Epoch 15/200 - Loss: 0.4808 - Val Acc: 0.6200 - Val Prec: 1.0000\n",
      "Epoch 16/200 - Loss: 0.4345 - Val Acc: 0.8400 - Val Prec: 1.0000\n",
      "Epoch 17/200 - Loss: 0.2735 - Val Acc: 0.9400 - Val Prec: 1.0000\n",
      "Epoch 18/200 - Loss: 0.3691 - Val Acc: 0.6300 - Val Prec: 0.5747\n",
      "Epoch 19/200 - Loss: 0.6828 - Val Acc: 0.5000 - Val Prec: 0.0000\n",
      "Epoch 20/200 - Loss: 0.6187 - Val Acc: 0.6300 - Val Prec: 0.5823\n",
      "Epoch 21/200 - Loss: 0.5964 - Val Acc: 0.6700 - Val Prec: 0.6164\n",
      "Epoch 22/200 - Loss: 0.5969 - Val Acc: 0.6400 - Val Prec: 0.5897\n",
      "Epoch 23/200 - Loss: 0.5946 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 24/200 - Loss: 0.5915 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 25/200 - Loss: 0.5886 - Val Acc: 0.6600 - Val Prec: 0.6053\n",
      "Epoch 26/200 - Loss: 0.5808 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 27/200 - Loss: 0.5723 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 28/200 - Loss: 0.5588 - Val Acc: 0.6500 - Val Prec: 0.5974\n",
      "Epoch 29/200 - Loss: 0.5586 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 30/200 - Loss: 0.5633 - Val Acc: 0.6500 - Val Prec: 0.5974\n",
      "Epoch 31/200 - Loss: 0.5615 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 32/200 - Loss: 0.5608 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 33/200 - Loss: 0.5515 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 34/200 - Loss: 0.5598 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 35/200 - Loss: 0.5516 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 36/200 - Loss: 0.5434 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 37/200 - Loss: 0.5575 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 38/200 - Loss: 0.5537 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 39/200 - Loss: 0.5595 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 40/200 - Loss: 0.5474 - Val Acc: 0.6400 - Val Prec: 0.5897\n",
      "Epoch 41/200 - Loss: 0.5463 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 42/200 - Loss: 0.5485 - Val Acc: 0.6800 - Val Prec: 0.6216\n",
      "Epoch 43/200 - Loss: 0.5440 - Val Acc: 0.6700 - Val Prec: 0.6164\n",
      "Epoch 44/200 - Loss: 0.5318 - Val Acc: 0.6500 - Val Prec: 0.5974\n",
      "Epoch 45/200 - Loss: 0.5313 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 46/200 - Loss: 0.5334 - Val Acc: 0.6500 - Val Prec: 0.8571\n",
      "Epoch 47/200 - Loss: 0.5833 - Val Acc: 0.5600 - Val Prec: 0.5319\n",
      "Epoch 48/200 - Loss: 0.5080 - Val Acc: 0.8200 - Val Prec: 0.7424\n",
      "Epoch 49/200 - Loss: 0.4944 - Val Acc: 0.8500 - Val Prec: 0.7778\n",
      "Epoch 50/200 - Loss: 0.4399 - Val Acc: 0.8500 - Val Prec: 0.8431\n",
      "Epoch 51/200 - Loss: 0.3701 - Val Acc: 0.9000 - Val Prec: 0.8704\n",
      "Epoch 52/200 - Loss: 0.3698 - Val Acc: 0.9100 - Val Prec: 0.8727\n",
      "Epoch 53/200 - Loss: 0.2797 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 54/200 - Loss: 0.2306 - Val Acc: 0.8900 - Val Prec: 0.8679\n",
      "Epoch 55/200 - Loss: 0.3268 - Val Acc: 0.8200 - Val Prec: 0.9706\n",
      "Epoch 56/200 - Loss: 0.3463 - Val Acc: 0.7600 - Val Prec: 0.8095\n",
      "Epoch 57/200 - Loss: 0.3761 - Val Acc: 0.9300 - Val Prec: 0.9216\n",
      "Epoch 58/200 - Loss: 0.3577 - Val Acc: 0.9000 - Val Prec: 0.8448\n",
      "Epoch 59/200 - Loss: 0.3127 - Val Acc: 0.8700 - Val Prec: 0.8627\n",
      "Epoch 60/200 - Loss: 0.2658 - Val Acc: 0.8200 - Val Prec: 0.8478\n",
      "Epoch 61/200 - Loss: 0.3214 - Val Acc: 0.9000 - Val Prec: 0.9545\n",
      "Epoch 62/200 - Loss: 0.2797 - Val Acc: 0.9100 - Val Prec: 0.9767\n",
      "Epoch 63/200 - Loss: 0.2768 - Val Acc: 0.9100 - Val Prec: 0.9362\n",
      "Epoch 64/200 - Loss: 0.2685 - Val Acc: 0.9200 - Val Prec: 0.9375\n",
      "Epoch 65/200 - Loss: 0.2662 - Val Acc: 0.8600 - Val Prec: 0.9500\n",
      "Epoch 66/200 - Loss: 0.2274 - Val Acc: 0.9100 - Val Prec: 0.9556\n",
      "Epoch 67/200 - Loss: 0.2534 - Val Acc: 0.9300 - Val Prec: 0.9574\n",
      "Epoch 68/200 - Loss: 0.2251 - Val Acc: 0.8800 - Val Prec: 0.9524\n",
      "Epoch 69/200 - Loss: 0.2268 - Val Acc: 0.9300 - Val Prec: 0.9574\n",
      "Epoch 70/200 - Loss: 0.2074 - Val Acc: 0.9400 - Val Prec: 0.9583\n",
      "Epoch 71/200 - Loss: 0.2170 - Val Acc: 0.8800 - Val Prec: 0.9524\n",
      "Epoch 72/200 - Loss: 0.1957 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 73/200 - Loss: 0.1858 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 74/200 - Loss: 0.1859 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 75/200 - Loss: 0.1792 - Val Acc: 0.9500 - Val Prec: 1.0000\n",
      "Epoch 76/200 - Loss: 0.1668 - Val Acc: 0.9700 - Val Prec: 0.9608\n",
      "Epoch 77/200 - Loss: 0.2065 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 78/200 - Loss: 0.1667 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 79/200 - Loss: 0.1658 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 80/200 - Loss: 0.1474 - Val Acc: 0.9700 - Val Prec: 1.0000\n",
      "Epoch 81/200 - Loss: 0.1385 - Val Acc: 0.9700 - Val Prec: 1.0000\n",
      "Epoch 82/200 - Loss: 0.1499 - Val Acc: 0.9300 - Val Prec: 0.8909\n",
      "Epoch 83/200 - Loss: 0.1868 - Val Acc: 0.8900 - Val Prec: 1.0000\n",
      "Epoch 84/200 - Loss: 0.1780 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 85/200 - Loss: 0.1552 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 86/200 - Loss: 0.1396 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 87/200 - Loss: 0.1365 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 88/200 - Loss: 0.1417 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 89/200 - Loss: 0.1459 - Val Acc: 0.9000 - Val Prec: 1.0000\n",
      "Epoch 90/200 - Loss: 0.2375 - Val Acc: 0.8800 - Val Prec: 0.8393\n",
      "Epoch 91/200 - Loss: 0.4000 - Val Acc: 0.8400 - Val Prec: 0.8400\n",
      "Epoch 92/200 - Loss: 0.2665 - Val Acc: 0.8900 - Val Prec: 0.8824\n",
      "Epoch 93/200 - Loss: 0.2783 - Val Acc: 0.9000 - Val Prec: 0.8846\n",
      "Epoch 94/200 - Loss: 0.2473 - Val Acc: 0.8900 - Val Prec: 0.9333\n",
      "Epoch 95/200 - Loss: 0.2258 - Val Acc: 0.9000 - Val Prec: 0.8846\n",
      "Epoch 96/200 - Loss: 0.2132 - Val Acc: 0.9300 - Val Prec: 0.9388\n",
      "Epoch 97/200 - Loss: 0.2029 - Val Acc: 0.9300 - Val Prec: 0.9388\n",
      "Epoch 98/200 - Loss: 0.2159 - Val Acc: 0.8900 - Val Prec: 0.9756\n",
      "Epoch 99/200 - Loss: 0.1996 - Val Acc: 0.9500 - Val Prec: 0.9787\n",
      "Epoch 100/200 - Loss: 0.2041 - Val Acc: 0.9600 - Val Prec: 0.9792\n",
      "Epoch 101/200 - Loss: 0.2090 - Val Acc: 0.9500 - Val Prec: 0.9787\n",
      "Epoch 102/200 - Loss: 0.1672 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 103/200 - Loss: 0.1404 - Val Acc: 0.9100 - Val Prec: 0.8868\n",
      "Epoch 104/200 - Loss: 0.1571 - Val Acc: 0.9100 - Val Prec: 0.9556\n",
      "Epoch 105/200 - Loss: 0.1398 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 106/200 - Loss: 0.1442 - Val Acc: 0.9500 - Val Prec: 0.9592\n",
      "Epoch 107/200 - Loss: 0.1521 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 108/200 - Loss: 0.1349 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 109/200 - Loss: 0.1379 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 110/200 - Loss: 0.1253 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 111/200 - Loss: 0.1391 - Val Acc: 0.8900 - Val Prec: 0.9756\n",
      "Epoch 112/200 - Loss: 0.2342 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 113/200 - Loss: 0.2121 - Val Acc: 0.9000 - Val Prec: 1.0000\n",
      "Epoch 114/200 - Loss: 0.1729 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 115/200 - Loss: 0.1591 - Val Acc: 0.9500 - Val Prec: 0.9592\n",
      "Epoch 116/200 - Loss: 0.1652 - Val Acc: 0.9300 - Val Prec: 0.8909\n",
      "Epoch 117/200 - Loss: 0.1531 - Val Acc: 0.9700 - Val Prec: 1.0000\n",
      "Epoch 118/200 - Loss: 0.1461 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 119/200 - Loss: 0.1569 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 120/200 - Loss: 0.1557 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 121/200 - Loss: 0.1491 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 122/200 - Loss: 0.1336 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 123/200 - Loss: 0.1364 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 124/200 - Loss: 0.1564 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 125/200 - Loss: 0.1340 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 126/200 - Loss: 0.1445 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 127/200 - Loss: 0.1297 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 128/200 - Loss: 0.1244 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 129/200 - Loss: 0.1307 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 130/200 - Loss: 0.1393 - Val Acc: 0.9600 - Val Prec: 0.9792\n",
      "Epoch 131/200 - Loss: 0.1345 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 132/200 - Loss: 0.1323 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 133/200 - Loss: 0.1367 - Val Acc: 0.9400 - Val Prec: 0.9583\n",
      "Epoch 134/200 - Loss: 0.1433 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 135/200 - Loss: 0.1376 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 136/200 - Loss: 0.1403 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 137/200 - Loss: 0.1573 - Val Acc: 0.9000 - Val Prec: 1.0000\n",
      "Epoch 138/200 - Loss: 0.1480 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 139/200 - Loss: 0.1275 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 140/200 - Loss: 0.1394 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 141/200 - Loss: 0.1307 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 142/200 - Loss: 0.1260 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 143/200 - Loss: 0.1254 - Val Acc: 0.9600 - Val Prec: 0.9600\n",
      "Epoch 144/200 - Loss: 0.1559 - Val Acc: 0.9000 - Val Prec: 0.8571\n",
      "Epoch 145/200 - Loss: 0.2234 - Val Acc: 0.9400 - Val Prec: 0.9074\n",
      "Epoch 146/200 - Loss: 0.1812 - Val Acc: 0.9000 - Val Prec: 1.0000\n",
      "Epoch 147/200 - Loss: 0.1608 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 148/200 - Loss: 0.1573 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 149/200 - Loss: 0.1600 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 150/200 - Loss: 0.1317 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 151/200 - Loss: 0.1321 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 152/200 - Loss: 0.1228 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 153/200 - Loss: 0.1333 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 154/200 - Loss: 0.1332 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 155/200 - Loss: 0.1285 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 156/200 - Loss: 0.1347 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 157/200 - Loss: 0.1221 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 158/200 - Loss: 0.1280 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 159/200 - Loss: 0.1571 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 160/200 - Loss: 0.1514 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 161/200 - Loss: 0.1231 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 162/200 - Loss: 0.1299 - Val Acc: 0.9000 - Val Prec: 1.0000\n",
      "Epoch 163/200 - Loss: 0.1327 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 164/200 - Loss: 0.1183 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 165/200 - Loss: 0.1250 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 166/200 - Loss: 0.1191 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 167/200 - Loss: 0.1181 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 168/200 - Loss: 0.1206 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 169/200 - Loss: 0.1302 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 170/200 - Loss: 0.1235 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 171/200 - Loss: 0.1253 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 172/200 - Loss: 0.1220 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 173/200 - Loss: 0.1234 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 174/200 - Loss: 0.1318 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 175/200 - Loss: 0.1226 - Val Acc: 0.9500 - Val Prec: 0.9412\n",
      "Epoch 176/200 - Loss: 0.1588 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 177/200 - Loss: 0.1336 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 178/200 - Loss: 0.1212 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 179/200 - Loss: 0.1243 - Val Acc: 0.9600 - Val Prec: 0.9600\n",
      "Epoch 180/200 - Loss: 0.1465 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 181/200 - Loss: 0.1295 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 182/200 - Loss: 0.1158 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 183/200 - Loss: 0.1256 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 184/200 - Loss: 0.1189 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 185/200 - Loss: 0.1194 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 186/200 - Loss: 0.1205 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 187/200 - Loss: 0.1180 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 188/200 - Loss: 0.1117 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 189/200 - Loss: 0.1175 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 190/200 - Loss: 0.1240 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 191/200 - Loss: 0.1161 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 192/200 - Loss: 0.1365 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 193/200 - Loss: 0.1207 - Val Acc: 0.9400 - Val Prec: 0.9583\n",
      "Epoch 194/200 - Loss: 0.1187 - Val Acc: 0.9400 - Val Prec: 0.9583\n",
      "Epoch 195/200 - Loss: 0.1156 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 196/200 - Loss: 0.1217 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 197/200 - Loss: 0.1225 - Val Acc: 0.9300 - Val Prec: 1.0000\n",
      "Epoch 198/200 - Loss: 0.1413 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 199/200 - Loss: 0.1520 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Epoch 200/200 - Loss: 0.1508 - Val Acc: 0.9600 - Val Prec: 1.0000\n",
      "Test Accuracy: 0.95000\n",
      "Test Precision: 1.00000\n",
      "Test Recall: 0.90000\n",
      "Test F1: 0.94737\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de logits obtidos: 100 amostras, 2 classes.\n",
      "Primeiras 10 linhas de logits:\n",
      "tensor([[-4.3608,  4.4112],\n",
      "        [-3.7462,  3.9963],\n",
      "        [-4.3594,  4.4109],\n",
      "        [ 0.0243, -0.2212],\n",
      "        [ 1.6355, -1.9354],\n",
      "        [ 0.7609, -0.7530],\n",
      "        [ 0.0428, -0.2415],\n",
      "        [-4.3672,  4.4165],\n",
      "        [ 5.1089, -4.8445],\n",
      "        [ 5.0027, -4.7874]])\n",
      "\n",
      "Novas colunas (logits, probabilidades) adicionadas ao test_df (primeiras 5 linhas):\n",
      "                                  file_content_in_il  vulnerable  \\\n",
      "0  class class_name1\\r\\n  private var1\\r\\n  publi...           1   \n",
      "1  var1 array\\r\\nvar1_0\\r\\nvar1_1 GET\\r\\nvar1_2\\r...           1   \n",
      "2  class class_name1\\r\\n  private var1\\r\\n  publi...           1   \n",
      "3  var1 POST\\r\\nvar2 unserialize var1\\r\\nvar2 mys...           0   \n",
      "4  var1 POST\\r\\nvar2 unserialize var1\\r\\nvar2 mys...           0   \n",
      "\n",
      "   logit_non_vulnerable  logit_vulnerable  prob_non_vulnerable  \\\n",
      "0             -4.360761          4.411232             0.000155   \n",
      "1             -3.746166          3.996269             0.000434   \n",
      "2             -4.359403          4.410905             0.000155   \n",
      "3              0.024348         -0.221184             0.561076   \n",
      "4              1.635492         -1.935384             0.972639   \n",
      "\n",
      "   prob_vulnerable  \n",
      "0         0.999845  \n",
      "1         0.999566  \n",
      "2         0.999845  \n",
      "3         0.438924  \n",
      "4         0.027361  \n"
     ]
    }
   ],
   "source": [
    "# %pip install transformers\n",
    "# %pip install datasets\n",
    "# %pip install accelerate\n",
    "# %pip install transformers[sentencepiece]\n",
    "# %pip install torch\n",
    "# %pip install scikit-learn\n",
    "# %pip install evaluate\n",
    "# %pip install nltk\n",
    "# %pip install pandas\n",
    "# %pip install sklearn\n",
    "# %pip install matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score # Importações adicionadas\n",
    "import matplotlib.pyplot as plt # Importado para exibir gráficos\n",
    "\n",
    "def load_data():\n",
    "    # Carregar DataFrames (este bloco está OK)\n",
    "    train_nvuln_df = pd.read_csv('../data/csv/train_com_id_il_nvuln.csv')\n",
    "    train_vuln_df = pd.read_csv('../data/csv/train_com_id_il_vuln.csv')\n",
    "    test_nvuln_df = pd.read_csv('../data/csv/test_com_id_il_nvuln.csv')\n",
    "    test_vuln_df = pd.read_csv('../data/csv/test_com_id_il_vuln.csv')\n",
    "\n",
    "    train_df = pd.concat([train_nvuln_df, train_vuln_df], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_df = pd.concat([test_nvuln_df, test_vuln_df], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    train_df['vulnerable'] = train_df['vulnerable'].astype(int)\n",
    "    test_df['vulnerable'] = test_df['vulnerable'].astype(int)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=1/9, random_state=42, shuffle=True, stratify=train_df['vulnerable'])\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def encode_snippet(snippet, vocab_map, max_len=77):\n",
    "    tokens = snippet.split()\n",
    "    token_ids = [vocab_map.get(token, 0) for token in tokens]\n",
    "    if len(token_ids) > max_len:\n",
    "        return token_ids[:max_len]\n",
    "    else:\n",
    "        return token_ids + [0] * (max_len - len(token_ids))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {'input_ids': encodings} # Mantém o dicionário para compatibilidade\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        # **ALTERAÇÃO CRUCIAL AQUI:** Labels devem ser torch.long para CrossEntropyLoss\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item # Retorna um dicionário\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, output_dim, dropout):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # output_dim = 2 é o que você precisa\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        final_output = lstm_out[:, -1, :] \n",
    "        out = self.fc(final_output)\n",
    "        # **REMOVIDO:** return self.sigmoid(out).squeeze(1)\n",
    "        # **ALTERAÇÃO CRUCIAL AQUI:** Retorna os logits brutos (batch_size, 2)\n",
    "        return out \n",
    "\n",
    "def evaluate_model(model, data_loader, device, validation=False):\n",
    "    model.eval()\n",
    "    # **ALTERAÇÃO CRUCIAL AQUI:** Usar CrossEntropyLoss\n",
    "    criterion = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader: # Batch é um dicionário aqui\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device) # Labels já são long do CustomDataset\n",
    "\n",
    "            outputs = model(input_ids) # Estes são os LOGITS (shape: batch_size, 2)\n",
    "            \n",
    "            loss = criterion(outputs, labels) \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Para obter as previsões, aplicar argmax nos logits\n",
    "            predictions = torch.argmax(outputs, dim=1) # Retorna o índice da classe com o maior logit\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Cálculos das métricas globais\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_labels)).sum() / len(all_labels)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    if validation:\n",
    "        return avg_loss, accuracy, precision \n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.5f}')\n",
    "    print(f'Test Precision: {precision:.5f}')\n",
    "    print(f'Test Recall: {recall:.5f}')\n",
    "    print(f'Test F1: {f1:.5f}')\n",
    "\n",
    "    # Gerar a matriz de confusão\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Não Vulnerável\", \"Vulnerável\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"Matriz de Confusão do Conjunto de Teste\")\n",
    "    plt.show() # Garante que o plot é exibido\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, device):\n",
    "    # **ALTERAÇÃO CRUCIAL AQUI:** Usar CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader: # Batch é um dicionário aqui\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device) # Labels já são long do CustomDataset\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids) # Estes são os LOGITS\n",
    "\n",
    "            # **ALTERAÇÃO CRUCIAL AQUI:** CrossEntropyLoss espera logits e labels long\n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss, val_acc, val_prec = evaluate_model(model, val_loader, device, validation=True)\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f} - Val Acc: {val_acc:.4f} - Val Prec: {val_prec:.4f}')\n",
    "\n",
    "def get_logits_per_class(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Executa o modelo nos dados fornecidos e retorna os logits brutos para cada classe.\n",
    "    \"\"\"\n",
    "    model.eval() # Coloca o modelo em modo de avaliação\n",
    "    all_logits = []\n",
    "    with torch.no_grad(): # Desativa o cálculo de gradientes\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device) # Acessa pelo nome da chave no dicionário\n",
    "            logits_batch = model(input_ids) # Obtém os logits diretamente\n",
    "            all_logits.append(logits_batch.cpu()) \n",
    "            \n",
    "    final_logits_tensor = torch.cat(all_logits, dim=0)\n",
    "    print(f\"Total de logits obtidos: {final_logits_tensor.shape[0]} amostras, {final_logits_tensor.shape[1]} classes.\")\n",
    "    return final_logits_tensor\n",
    "\n",
    "def train_test_and_save():\n",
    "    # Carregar os dados\n",
    "    train_df, val_df, test_df = load_data()\n",
    "    all_train_tokens = []\n",
    "    for snippet in train_df['file_content_in_il']:\n",
    "        all_train_tokens.extend(snippet.split())\n",
    "\n",
    "    counter = Counter(all_train_tokens)\n",
    "    vocab_size_limit = 5000 \n",
    "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(counter.most_common(vocab_size_limit))}\n",
    "\n",
    "    train_encodings = [encode_snippet(snippet, vocab) for snippet in train_df['file_content_in_il']]\n",
    "    val_encodings = [encode_snippet(snippet, vocab) for snippet in val_df['file_content_in_il']]\n",
    "    test_encodings = [encode_snippet(snippet, vocab) for snippet in test_df['file_content_in_il']]\n",
    "\n",
    "    # Definição do Device e Hiperparâmetros (este bloco está OK, apenas movido para a ordem correta)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "    # Hiperparâmetros\n",
    "    vocab_size = len(vocab) + 1 # Usa o vocab que já foi construído\n",
    "    embedding_dim = 64\n",
    "    hidden_dim = 64\n",
    "    num_layers = 5\n",
    "    output_dim = 2 # Perfeito para logits de 2 classes\n",
    "    dropout = 0.5\n",
    "    lr = 0.003\n",
    "    epochs = 200\n",
    "    batch_size = 77\n",
    "\n",
    "    # Criação de Datasets e DataLoaders (este bloco está OK)\n",
    "    train_dataset = CustomDataset(train_encodings, train_df['vulnerable'].tolist())\n",
    "    val_dataset = CustomDataset(val_encodings, val_df['vulnerable'].tolist())\n",
    "    test_dataset = CustomDataset(test_encodings, test_df['vulnerable'].tolist())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size) # Usar batch_size aqui também é mais seguro\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size) # Usar batch_size aqui também é mais seguro\n",
    "\n",
    "    # Criar e Treinar/Avaliar o modelo\n",
    "    model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, num_layers, output_dim, dropout)\n",
    "    train_model(model, train_loader, val_loader, epochs, lr, device)\n",
    "    evaluate_model(model, test_loader, device)\n",
    "\n",
    "    model_save_path = \"lstm_model.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"\\nModelo final guardado em: {model_save_path}\")\n",
    "\n",
    "\n",
    "    # A partir daqui obtém-se os logits de novas instâncias\n",
    "\n",
    "    # ----------------- #\n",
    "    inference_dataset = CustomDataset(test_encodings, test_df['vulnerable'].tolist())\n",
    "    # Usar um batch_size que pegue todo o dataset de uma vez é bom para inferência se a memória permitir.\n",
    "    inference_loader = DataLoader(inference_dataset, batch_size=len(inference_dataset), shuffle=False)\n",
    "\n",
    "    logits_for_new_instances = get_logits_per_class(model, inference_loader, device)\n",
    "\n",
    "    print(\"Primeiras 10 linhas de logits:\")\n",
    "    print(logits_for_new_instances[:10])\n",
    "\n",
    "    # Extrair os logits para cada classe e adicionar ao DataFrame\n",
    "    logit_non_vulnerable = logits_for_new_instances[:, 0].cpu().numpy()\n",
    "    logit_vulnerable = logits_for_new_instances[:, 1].cpu().numpy()\n",
    "\n",
    "    # Calcular probabilidades (se precisar delas para a heurística)\n",
    "    probabilities_per_class = torch.softmax(logits_for_new_instances, dim=1)\n",
    "    prob_non_vulnerable = probabilities_per_class[:, 0].cpu().numpy()\n",
    "    prob_vulnerable = probabilities_per_class[:, 1].cpu().numpy()\n",
    "\n",
    "    if logits_for_new_instances.shape[0] == len(test_df):\n",
    "        test_df['logit_non_vulnerable'] = logit_non_vulnerable\n",
    "        test_df['logit_vulnerable'] = logit_vulnerable\n",
    "        test_df['prob_non_vulnerable'] = prob_non_vulnerable\n",
    "        test_df['prob_vulnerable'] = prob_vulnerable\n",
    "        \n",
    "        print(\"\\nNovas colunas (logits, probabilidades) adicionadas ao test_df (primeiras 5 linhas):\")\n",
    "        print(test_df[['file_content_in_il', 'vulnerable', \n",
    "                    'logit_non_vulnerable', 'logit_vulnerable',\n",
    "                    'prob_non_vulnerable', 'prob_vulnerable']].head())\n",
    "    else:\n",
    "        print(\"Número de logits do modelo não corresponde ao número de linhas no test_df. Verifique a consistência dos dados.\")\n",
    "\n",
    "    # ----------------- #\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
